DeepMind, the Alphabet Inc. owned artificial intelligence company best known for creating software capable of beating the world’s best players at the strategy game Go, has targeted the science fiction video game StarCraft II as its next big research milestone. But so far, space is proving a difficult frontier for the company’s algorithms. DeepMind’s existing algorithms, including those that performed with super-human skill across a host of classic Atari titles, “cannot win a single game against the easiest built-in AI,” in StarCraft II let alone challenge skilled humans, the company said in a blog post Wednesday. The built-in agents, which are created by StarCraft publisher Activision Blizzard Inc., use hard-coded rules to determine their game play rather than the kinds of advanced machine learning techniques the London-based DeepMind specializes in. The company said new breakthroughs in machine learning would be required for its software agents to master the game.Just how close DeepMind may be to such breakthroughs, the blog post didn’t reveal. The algorithm that mastered the Atari games was unveiled in June 2016. Since then DeepMind has published a number of research papers that hint it may be closing in on creating software capable of many of the tasks – such as prioritizing goals, long-term planning, and memory – that any system will need in order to play StarCraft II successfully. The company said in its blog post that its existing algorithms performed well at learning some basic steps – such as moving around the game environment and selecting units – that will be critical to mastering the game.Games have long served as milestones for computer science research. StarCraft is considered an important target for machine learning researchers because, unlike Go, in which both players can see the entire board and take turns moving pieces, players in StarCraft cannot see what is happening in the entire game environment at one time and both players move their units simultaneously. The game also requires players to carry out sub-tasks, such as building structures and mining resources, while also conducting reconnaissance, mounting attacks and defending territory. To succeed, a player needs to have a good memory, prioritize among tasks, and plan under conditions of uncertainty. Because of these factors, StarCraft II comes much closer to approximating many real-world situations than games such as chess, Go or even Poker. StarCraft II is also used in e-sports competitions, so there are highly-skilled human opponents with which an artificial intelligence can match wits.In order to help computer scientists use StarCraft II as a testbed for artificial intelligence, DeepMind has partnered with Activision Blizzard, which is based in Santa Monica, California, to create an interface that allows outside software to access and play the game. The two companies unveiled that interface, along with a set of tools to help other computer scientists train AI agents to play the game, at a machine learning conference in Australia Thursday. “We’ve learned a lot during our collaboration with DeepMind on this project, and we’re very excited to get these tools in your hands to see what amazing things we can create together,” Blizzard wrote in a separate blog post also published Wednesday.Among the tools Activision Blizzard is making public are a dataset of anonymized game replays – essentially recordings of humans playing the game – that computer scientist will be able to use to help train their systems. “One technique that we know allows our agents to learn stronger policies is imitation learning,” DeepMind said in its blog post. “This kind of training will soon be far easier thanks to Blizzard, which has committed to on-going releases of hundreds of thousands of anonymized replays.”DeepMind also said it was releasing a series of “mini-game” environments that will help researchers train their AI agents on basic components of the game. The company’s decision to make its StarCraft II toolsets available to researchers for free differs from the more proprietary approach the company took when it was first working on algorithms that could master Atari games and Go. It follows efforts by other companies, such as Facebook and Microsoft, to open game environments, including the original StarCraft game and the game Minecraft, to the entire AI research community.